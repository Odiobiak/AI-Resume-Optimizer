{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPieQyBcCBtycs49jApghHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Odiobiak/AI-Resume-Optimizer/blob/main/Resume_Optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKYs3g2jFYMJ"
      },
      "source": [
        "# The Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdGaIIpaFjiu"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai python-docx pyPDF2 sklearn\n",
        "#!pip install google-generativeai==0.3.1\n",
        "#!pip install google-genai -U\n",
        "#!pip install PyPDF2\n",
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXHwri5QF6WQ"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import PyPDF2\n",
        "import docx\n",
        "import re\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import textwrap\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ETeEqDOG8qI"
      },
      "outputs": [],
      "source": [
        "# set up the model\n",
        "genai.configure(api_key=\"AIzaSyCr7B-Ox86HFFDqodh2p2pruSTrmgN9MD4\")\n",
        "\n",
        "generation_config ={\n",
        "    \"temperature\": 0.5,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"top_k\": 40,\n",
        "    \"top_p\": 0.95\n",
        "}\n",
        "\n",
        "\n",
        "# adding safety features\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    'gemini-2.0-flash-001',\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwL45ZrvHLGY"
      },
      "outputs": [],
      "source": [
        "# Function to extract the text from the uploaded resume, include pdf, word or text format\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    doc = docx.Document(docx_path)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "# To extract different versions of the resume\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith('.pdf'):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith('.docx'):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    else:\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SLH5RSlHbd9"
      },
      "outputs": [],
      "source": [
        "# Using embedding to make sure the text fits the model\n",
        "def get_embedding(text):\n",
        "    truncated_text = text[:10000]\n",
        "    result = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=truncated_text,\n",
        "        task_type=\"retrieval_document\"\n",
        "    )\n",
        "    return result['embedding']\n",
        "\n",
        "# use cosine to calculate similarity between two texts\n",
        "def calculate_similarity(text1, text2):\n",
        "    emb1 = get_embedding(text1)\n",
        "    emb2 = get_embedding(text2)\n",
        "    return cosine_similarity([emb1], [emb2])[0][0]\n",
        "\n",
        "\n",
        "\n",
        "# analyse and refine the resume\n",
        "# Passing the prompt to Returns structured analysis with: match score, strengths, gaps, and recommendations\n",
        "def analyze_alignment(resume_text, jd_text):\n",
        "\n",
        "    prompt = textwrap.dedent(f\"\"\"\n",
        "    **Resume-Job Description Alignment Analysis**\n",
        "\n",
        "    Analyze how well this resume matches the job description by examining:\n",
        "    - Required skills/technologies\n",
        "    - Years and type of experience\n",
        "    - Education/certifications\n",
        "    - Keywords and terminology\n",
        "    - Soft skills and cultural fit\n",
        "\n",
        "    **Resume Content:**\n",
        "    {resume_text[:10000]}  # Limiting to first 10k chars for Gemini context\n",
        "\n",
        "    **Job Description Content:**\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    Provide your analysis in this exact format:\n",
        "\n",
        "    [Explanation of overall match qualities]\n",
        "\n",
        "    ### Key Strengths:\n",
        "    - [Strength 1 with specific evidence] from resume\n",
        "    - [Strength 2 with specific evidence]\n",
        "    - [Strength 3 with specific evidence]\n",
        "\n",
        "    ### Critical Gaps:\n",
        "    - [Missing requirement 1 with impact] (Critical/Important/Nice-to-Have)\n",
        "    - [Missing requirement 2 with impact]\n",
        "    - [Missing requirement 3 with impact]\n",
        "\n",
        "    ### Improvement Recommendations:\n",
        "    - [Actionable suggestion 1] (most impactful)\n",
        "    - [Actionable suggestion 2]\n",
        "    - [Actionable suggestion 3]\n",
        "\n",
        "    ### Keyword Optimization:\n",
        "    [List of important JD keywords missing from resume]\n",
        "    \"\"\")\n",
        "\n",
        "    # Error catch\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Analysis failed: {str(e)}\"\n",
        "\n",
        "# Refine the resume to match the job description.\n",
        "# This Maintains original information while optimizing for the JD\n",
        "\n",
        "def refine_resume(resume_text, jd_text):\n",
        "\n",
        "    \"\"\"Responsible resume refinement with compatibility check\"\"\"\n",
        "    # First check compatibility\n",
        "    compat = calculate_compatibility(resume_text, jd_text)\n",
        "\n",
        "    if compat['score'] < 40:  # Threshold for poor match\n",
        "        return {\n",
        "            'status': 'poor_match',\n",
        "            'message': f\"Low compatibility ({compat['score']}%) {compat['reason']}\",\n",
        "            'suggested_roles': compat['suggested_roles'],\n",
        "            'refined_resume': None\n",
        "        }\n",
        "\n",
        "    prompt = textwrap.dedent(f\"\"\"\n",
        "    **Resume Refinement Task**\n",
        "\n",
        "    Carefully refine this resume for the target job:\n",
        "\n",
        "\n",
        "    You are a professional resume writer. Rewrite this resume to better match the\n",
        "    target job description while:\n",
        "    1. Preserve all factual information\n",
        "    2. Only add skills/experiences that can be reasonably inferred\n",
        "    3. Never falsify qualifications\n",
        "    4. Prioritize keywords from the job description\n",
        "    5. Keep original formatting style and structure\n",
        "    6. Reordering content to highlight relevant experience first\n",
        "    7. Quantifying achievements where possible\n",
        "\n",
        "    **Original Resume:**\n",
        "    {resume_text[:10000]}\n",
        "\n",
        "    **Target Job Description:**\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    **MODIFICATION GUIDELINES:**\n",
        "    - Incorporate at least 3 key terms from the JD\n",
        "    - Combine skills to a 'Relevant Skills' section, limit the number of skills to the resonable for a resume\n",
        "    - Ensure work experience highlights JD-relevant accomplishments\n",
        "    - Optimize the professional summary for this role\n",
        "\n",
        "    Return ONLY the refined resume text with no additional commentary or analysis.\n",
        "    Maintain the same format as the original (bullet points, sections, etc).\n",
        "    \"\"\")\n",
        "\n",
        "# Error catch\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        # Clean up response to ensure only resume content\n",
        "        refined = response.text\n",
        "        if refined.startswith(\"```\"):\n",
        "            refined = refined[:-3]\n",
        "        return {\n",
        "            'status': 'success',\n",
        "            'compatibility_score': compat['score'],\n",
        "            'refined_resume': refined.strip(),\n",
        "            'analysis': compat['reason']\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        # Print or log the error\n",
        "        print(f\"Refinement failed: {str(e)}\")  # Print or log the error\n",
        "\n",
        "\n",
        "        # Return a dictionary indicating failure\n",
        "        return {\n",
        "            'status': 'error',\n",
        "            'message': f\"Refinement failed: {str(e)}\",\n",
        "            'refined_resume': None\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkeNlcwSHVhr"
      },
      "outputs": [],
      "source": [
        "def calculate_compatibility(resume_text, jd_text):\n",
        "    \"\"\"Returns compatibility score and reason\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze compatibility between this resume and job description:\n",
        "\n",
        "    RESUME:\n",
        "    {resume_text[:10000]}\n",
        "\n",
        "    JOB DESCRIPTION:\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    Respond STRICTLY in this format:\n",
        "\n",
        "    COMPATIBILITY_SCORE: [0-100]%\n",
        "    REASON: [concise mismatch explanation]\n",
        "    SUGGGESTED_ROLES: [Role1] | [Role2] | [Role3]\n",
        "\n",
        "    Example:\n",
        "    COMPATIBILITY_SCORE: 5%\n",
        "    REASON: The resume is for an HR Generalist while the job description is for a Data Analyst.\n",
        "    SUGGGESTED_ROLES: HR Data Specialist | People Analytics | Recruitment Coordinator\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return parse_compatibility_response(response.text)\n",
        "\n",
        "\n",
        "def parse_compatibility_response(text):\n",
        "    \"\"\"More robust parsing\"\"\"\n",
        "    result = {\n",
        "        'score': 0,\n",
        "        'reason': \"No analysis available\",\n",
        "        'suggested_roles': [\"HR Data Specialist\", \"People Analytics\", \"Recruitment Coordinator\"]  # Defaults\n",
        "    }\n",
        "\n",
        "    # Extract score\n",
        "    score_match = re.search(r\"COMPATIBILITY_SCORE:\\s*(\\d+)%\", text)\n",
        "    if score_match:\n",
        "        result['score'] = int(score_match.group(1))\n",
        "\n",
        "    # Extract reason\n",
        "    reason_match = re.search(r\"REASON:\\s*(.+?)(?:\\n|SUGGESTED_ROLES:|$)\", text, re.DOTALL)\n",
        "    if reason_match:\n",
        "        result['reason'] = reason_match.group(1).strip()\n",
        "\n",
        "    # Extract roles (handles various delimiters)\n",
        "    roles_match = re.search(r\"SUGGESTED_ROLES:\\s*(.+)\", text)\n",
        "    if roles_match:\n",
        "        roles = roles_match.group(1)\n",
        "        result['suggested_roles'] = [r.strip() for r in re.split(r\"\\||,|;\", roles) if r.strip()]\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkBTtx9NHx87"
      },
      "outputs": [],
      "source": [
        "def generate_cover_letter(refined_resume, jd_text):\n",
        "    \"\"\"Creates tailored cover letter\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Write a professional cover letter combining:\n",
        "\n",
        "    CANDIDATE QUALIFICATIONS:\n",
        "    {refined_resume[:10000]}\n",
        "\n",
        "    JOB REQUIREMENTS:\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    Guidelines:\n",
        "    1. Make sure to include know information e.g name, address, phone number etc from the resume\n",
        "    2. 3-4 concise paragraphs\n",
        "    3. Highlight 3 key matching qualifications\n",
        "    4. Address potential gaps diplomatically\n",
        "    5. Express interest in the position and company\n",
        "    6. Include a passionate closing statement\n",
        "\n",
        "    Return ONLY the cover letter text.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b4GZC6bH5d8"
      },
      "outputs": [],
      "source": [
        "# Main function\n",
        "def main():\n",
        "    print(\" Resume Analysis & Optimization Tool\")\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "    # File uploads\n",
        "    print(\"\\n STEP 1: Upload your resume (PDF/DOCX/TXT):\")\n",
        "    uploaded_resume = files.upload()\n",
        "    resume_file = next(iter(uploaded_resume))\n",
        "    resume_text = extract_text(resume_file)\n",
        "\n",
        "    print(\"\\n STEP 2: Upload the job description (PDF/DOCX/TXT):\")\n",
        "    uploaded_jd = files.upload()\n",
        "    jd_file = next(iter(uploaded_jd))\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    # Calculate embedding similarity\n",
        "    print(\"\\n Analyzing documents...\")\n",
        "    similarity_score = calculate_similarity(resume_text, jd_text)\n",
        "    print(f\"\\n Semantic Match Score: {similarity_score*100:.1f}% \\n\")\n",
        "\n",
        "  # calling the refine resume funct\n",
        "    optimized_resume = refine_resume(resume_text, jd_text)\n",
        "\n",
        "    if optimized_resume['status'] == 'poor_match':\n",
        "      print(f\"\\n⚠️ Compatibility Alert: \\n {optimized_resume['message']}\\n\")\n",
        "      if optimized_resume['suggested_roles']:\n",
        "        print(\"\\n Suggested Alternative Roles:\")\n",
        "        for i, role in enumerate(optimized_resume['suggested_roles'][:3], 1):\n",
        "            print(f\"{i}. {role}\")\n",
        "      return\n",
        "\n",
        "    else:  # Detailed analysis\n",
        "      print(f\" Compatibility Score: {optimized_resume['compatibility_score']}% \\n\")\n",
        "      print(\"\\n Detailed Analysis:\")\n",
        "      analysis = analyze_alignment(resume_text, jd_text)\n",
        "      print(analysis)\n",
        "\n",
        "    # Generate cover letter for compatible matches\n",
        "      cover_letter = generate_cover_letter(\n",
        "          optimized_resume['refined_resume'],\n",
        "          jd_text\n",
        "      )\n",
        "\n",
        "      # Resume refinement\n",
        "      print(\"\\n Generating optimized resume...\")\n",
        "      print(\"\\n OPTIMIZED RESUME:\")\n",
        "      print(\"-------------------\")\n",
        "      print(optimized_resume['refined_resume'])\n",
        "      print(\"\\n Generating COVER LETTER...\")\n",
        "      print(\"\\n COVER LETTER:\")\n",
        "      print(\"--------------\")\n",
        "      print(cover_letter)\n",
        "\n",
        "      # Save and offer download\n",
        "      with open('optimized_resume.txt', 'w') as f:\n",
        "        f.write(optimized_resume['refined_resume'])\n",
        "      print(\"\\n Downloaded your optimized resume:\")\n",
        "      files.download('optimized_resume.txt')\n",
        "\n",
        "      with open('cover_letter.txt', 'w') as f:\n",
        "        f.write(cover_letter)\n",
        "      print(\"\\n Downloaded your cover letter:\")\n",
        "      files.download('cover_letter.txt')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prototype\n"
      ],
      "metadata": {
        "id": "qhXs2ipvYlTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install google-generativeai python-docx pyPDF2 sklearn\n",
        "#!pip install google-generativeai==0.3.1\n",
        "#!pip install google-genai -U\n",
        "#!pip install PyPDF2\n",
        "#!pip install python-docx\n"
      ],
      "metadata": {
        "id": "5BY7yBALs2hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import PyPDF2\n",
        "import docx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import textwrap\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "aarixq_8sB41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up the model\n",
        "genai.configure(api_key=\"AIzaSyCr7B-Ox86HFFDqodh2p2pruSTrmgN9MD4\")\n",
        "\n",
        "generation_config ={\n",
        "    \"temperature\": 0.5,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"top_k\": 40,\n",
        "    \"top_p\": 0.95\n",
        "}\n",
        "\n",
        "\n",
        "# adding safety features\n",
        "safety_settings = [\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"},\n",
        "]\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    'gemini-2.0-flash-001',\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "DUT_QL8zv5bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract the text from the uploaded resume, include pdf, word or text format\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    doc = docx.Document(docx_path)\n",
        "    full_text = []\n",
        "    for para in doc.paragraphs:\n",
        "        full_text.append(para.text)\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "# To extract different versions of the resume\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith('.pdf'):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith('.docx'):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    else:\n",
        "        with open(file_path, 'r') as file:\n",
        "            return file.read()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfDU0j4j0j_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_compatibility(resume_text, jd_text):\n",
        "    \"\"\"Returns compatibility score and reason\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze compatibility between this resume and job description:\n",
        "\n",
        "    RESUME:\n",
        "    {resume_text[:10000]}\n",
        "\n",
        "    JOB DESCRIPTION:\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    Respond in this exact format:\n",
        "\n",
        "    COMPATIBILITY_SCORE: 0-100%\n",
        "    REASON: [Brief explanation of key mismatches]\n",
        "    SUGGESTED_ROLES: [3 alternative job titles that better match the resume]\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt)\n",
        "    return parse_compatibility_response(response.text)\n",
        "\n",
        "def parse_compatibility_response(text):\n",
        "    \"\"\"Extracts structured data from Gemini response\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    result = {\n",
        "        'score': 0,\n",
        "        'reason': \"Not analyzed\",\n",
        "        'suggested_roles': []\n",
        "    }\n",
        "    for line in lines:\n",
        "        if 'COMPATIBILITY_SCORE:' in line:\n",
        "            result['score'] = int(line.split(':')[1].replace('%','').strip())\n",
        "        elif 'REASON:' in line:\n",
        "            result['reason'] = line.split(':')[1].strip()\n",
        "        elif 'SUGGESTED_ROLES:' in line:\n",
        "            result['suggested_roles'] = [x.strip() for x in line.split(':')[1].split(',')]\n",
        "    return result\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W_RoO66anl-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using embedding to make sure the text fits the model\n",
        "def get_embedding(text):\n",
        "    truncated_text = text[:10000]\n",
        "    result = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=truncated_text,\n",
        "        task_type=\"retrieval_document\"\n",
        "    )\n",
        "    return result['embedding']\n",
        "\n",
        "# use cosine to calculate similarity between two texts\n",
        "def calculate_similarity(text1, text2):\n",
        "    emb1 = get_embedding(text1)\n",
        "    emb2 = get_embedding(text2)\n",
        "    return cosine_similarity([emb1], [emb2])[0][0]\n",
        "\n",
        "\n",
        "\n",
        "# analyse and refine the resume\n",
        "# Passing the prompt to Returns structured analysis with: match score, strengths, gaps, and recommendations\n",
        "def analyze_alignment(resume_text, jd_text):\n",
        "\n",
        "    prompt = textwrap.dedent(f\"\"\"\n",
        "    **Resume-Job Description Alignment Analysis**\n",
        "\n",
        "    Analyze how well this resume matches the job description by examining:\n",
        "    - Required skills/technologies\n",
        "    - Years and type of experience\n",
        "    - Education/certifications\n",
        "    - Keywords and terminology\n",
        "    - Soft skills and cultural fit\n",
        "\n",
        "    **Resume Content:**\n",
        "    {resume_text[:10000]}  # Limiting to first 10k chars for Gemini context\n",
        "\n",
        "    **Job Description Content:**\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    Provide your analysis in this exact format:\n",
        "\n",
        "    [Explanation of overall match qualities]\n",
        "\n",
        "    ### Key Strengths:\n",
        "    - [Strength 1 with specific evidence] from resume\n",
        "    - [Strength 2 with specific evidence]\n",
        "    - [Strength 3 with specific evidence]\n",
        "\n",
        "    ### Critical Gaps:\n",
        "    - [Missing requirement 1 with impact] (Critical/Important/Nice-to-Have)\n",
        "    - [Missing requirement 2 with impact]\n",
        "    - [Missing requirement 3 with impact]\n",
        "\n",
        "    ### Improvement Recommendations:\n",
        "    - [Actionable suggestion 1] (most impactful)\n",
        "    - [Actionable suggestion 2]\n",
        "    - [Actionable suggestion 3]\n",
        "\n",
        "    ### Keyword Optimization:\n",
        "    [List of important JD keywords missing from resume]\n",
        "    \"\"\")\n",
        "\n",
        "    # Error catch\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Analysis failed: {str(e)}\"\n",
        "\n",
        "# Refine the resume to match the job description.\n",
        "# This Maintains original information while optimizing for the JD\n",
        "\n",
        "def refine_resume(resume_text, jd_text):\n",
        "\n",
        "    \"\"\"Responsible resume refinement with compatibility check\"\"\"\n",
        "    # First check compatibility\n",
        "    compat = calculate_compatibility(resume_text, jd_text)\n",
        "\n",
        "    if compat['score'] < 40:  # Threshold for poor match\n",
        "        return {\n",
        "            'status': 'poor_match',\n",
        "            'message': f\"Low compatibility ({compat['score']}%) \\n {compat['reason']}\",\n",
        "            'suggested_roles': compat['suggested_roles'],\n",
        "            'refined_resume': None\n",
        "        }\n",
        "\n",
        "    prompt = textwrap.dedent(f\"\"\"\n",
        "    **Resume Refinement Task**\n",
        "\n",
        "    Carefully refine this resume for the target job:\n",
        "\n",
        "\n",
        "    You are a professional resume writer. Rewrite this resume to better match the\n",
        "    target job description while:\n",
        "    1. Preserve all factual information\n",
        "    2. Only add skills/experiences that can be reasonably inferred\n",
        "    3. Never falsify qualifications\n",
        "    4. Prioritize keywords from the job description\n",
        "    5. Keep original formatting style and structure\n",
        "    6. Reordering content to highlight relevant experience first\n",
        "    7. Quantifying achievements where possible\n",
        "\n",
        "    **Original Resume:**\n",
        "    {resume_text[:10000]}\n",
        "\n",
        "    **Target Job Description:**\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    **MODIFICATION GUIDELINES:**\n",
        "    - Incorporate at least 3 key terms from the JD\n",
        "    - Refine the \"Skills\" section to \" Relevant Skill\" if missing\n",
        "    - Ensure work experience highlights JD-relevant accomplishments\n",
        "    - Optimize the professional summary for this role\n",
        "\n",
        "    Return ONLY the refined resume text with no additional commentary or analysis.\n",
        "    Maintain the same format as the original (bullet points, sections, etc).\n",
        "    \"\"\")\n",
        "\n",
        "# Error catch\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        # Clean up response to ensure only resume content\n",
        "        refined = response.text\n",
        "        if refined.startswith(\"```\"):\n",
        "            refined = refined[:-3]\n",
        "        return {\n",
        "            'status': 'success',\n",
        "            'compatibility_score': compat['score'],\n",
        "            'refined_resume': refined.strip(),\n",
        "            'analysis': compat['reason']\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        # Print or log the error\n",
        "        print(f\"Refinement failed: {str(e)}\")  # Print or log the error\n",
        "\n",
        "\n",
        "        # Return a dictionary indicating failure\n",
        "        return {\n",
        "            'status': 'error',\n",
        "            'message': f\"Refinement failed: {str(e)}\",\n",
        "            'refined_resume': None\n",
        "        }"
      ],
      "metadata": {
        "id": "amY8QzHA9tKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cover_letter(refined_resume, jd_text):\n",
        "    \"\"\"Creates tailored cover letter\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Write a professional cover letter combining:\n",
        "\n",
        "    CANDIDATE QUALIFICATIONS:\n",
        "    {refined_resume[:10000]}\n",
        "\n",
        "    JOB REQUIREMENTS:\n",
        "    {jd_text[:10000]}\n",
        "\n",
        "    Guidelines:\n",
        "    1. 3-4 concise paragraphs\n",
        "    2. Highlight 3 key matching qualifications\n",
        "    3. Address potential gaps diplomatically\n",
        "    4. Use formal business letter format\n",
        "    5. Include know information e.g name, address, phone number etc from the resume\n",
        "\n",
        "    Return ONLY the cover letter text.\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text"
      ],
      "metadata": {
        "id": "HW99OENrrPV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function\n",
        "def main():\n",
        "    print(\" Resume Analysis & Optimization Tool\")\n",
        "    print(\"-------------------------------------\")\n",
        "\n",
        "    # File uploads\n",
        "    print(\"\\n STEP 1: Upload your resume (PDF/DOCX/TXT):\")\n",
        "    uploaded_resume = files.upload()\n",
        "    resume_file = next(iter(uploaded_resume))\n",
        "    resume_text = extract_text(resume_file)\n",
        "\n",
        "    print(\"\\n STEP 2: Upload the job description (PDF/DOCX/TXT):\")\n",
        "    uploaded_jd = files.upload()\n",
        "    jd_file = next(iter(uploaded_jd))\n",
        "    jd_text = extract_text(jd_file)\n",
        "\n",
        "    # Calculate embedding similarity\n",
        "    print(\"\\n Analyzing documents...\")\n",
        "    similarity_score = calculate_similarity(resume_text, jd_text)\n",
        "    print(f\"\\n Semantic Match Score: {similarity_score*100:.1f}% \\n\")\n",
        "\n",
        "  # calling the refine resume funct\n",
        "    optimized_resume = refine_resume(resume_text, jd_text)\n",
        "\n",
        "    if optimized_resume['status'] == 'poor_match':\n",
        "      print(f\"{optimized_resume['message']}\")\n",
        "      print(\"\\n Suggested alternative roles:\")\n",
        "      for role in optimized_resume['suggested_roles']:\n",
        "          print(f\"- {role}\")\n",
        "      return\n",
        "\n",
        "    else:  # Detailed analysis\n",
        "      print(f\" Compatibility Score: {optimized_resume['compatibility_score']}%\")\n",
        "      print(\"\\n Detailed Analysis:\")\n",
        "      analysis = analyze_alignment(resume_text, jd_text)\n",
        "      print(analysis)\n",
        "\n",
        "    # Generate cover letter for compatible matches\n",
        "      cover_letter = generate_cover_letter(\n",
        "          optimized_resume['refined_resume'],\n",
        "          jd_text\n",
        "      )\n",
        "\n",
        "      # Resume refinement\n",
        "      print(\"\\n Generating optimized resume...\")\n",
        "      print(\"\\n OPTIMIZED RESUME:\")\n",
        "      print(\"-------------------\")\n",
        "      print(optimized_resume['refined_resume'])\n",
        "      print(\"\\n Generating COVER LETTER...\")\n",
        "      print(\"\\n COVER LETTER:\")\n",
        "      print(\"--------------\")\n",
        "      print(cover_letter)\n",
        "\n",
        "      # Save and offer download\n",
        "      with open('optimized_resume.txt', 'w') as f:\n",
        "        f.write(optimized_resume['refined_resume'])\n",
        "      print(\"\\n Downloaded your optimized resume:\")\n",
        "      files.download('optimized_resume.txt')\n",
        "\n",
        "      with open('cover_letter.txt', 'w') as f:\n",
        "        f.write(cover_letter)\n",
        "      print(\"\\n Downloaded your cover letter:\")\n",
        "      files.download('cover_letter.txt')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oznssTtn3ebV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "fc116a26-34ae-4f1a-f900-1828a504b220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Resume Analysis & Optimization Tool\n",
            "-------------------------------------\n",
            "\n",
            " STEP 1: Upload your resume (PDF/DOCX/TXT):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63cead04-88af-4070-aa51-ab8f7f51b734\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63cead04-88af-4070-aa51-ab8f7f51b734\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pm resume.docx to pm resume (1).docx\n",
            "\n",
            " STEP 2: Upload the job description (PDF/DOCX/TXT):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1375e085-fda6-4c07-b82c-5a3825c1ba82\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1375e085-fda6-4c07-b82c-5a3825c1ba82\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data Engineer Job Description.docx to Data Engineer Job Description (1).docx\n",
            "\n",
            " Analyzing documents...\n",
            "\n",
            " Semantic Match Score: 60.5% \n",
            "\n",
            "Low compatibility (20%) \n",
            " The resume highlights extensive program management experience, focusing on leadership, project delivery, and strategic initiatives. The job description is for a Data Engineer, requiring strong technical skills in Python, SQL, data warehousing, and specific tools like Airflow and Snowflake. The resume lacks demonstrable experience in these technical areas, creating a significant mismatch.\n",
            "\n",
            " Suggested alternative roles:\n",
            "- \n"
          ]
        }
      ]
    }
  ]
}